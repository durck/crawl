# Crawl Configuration File
# Copy to ~/.crawl.conf or set CRAWL_CONFIG=/path/to/config

# ============================================
# General Settings
# ============================================

# Maximum recursion depth for archives/documents
MAX_RECURSION_DEPTH=5

# Default number of threads for crawl_mt.sh
DEFAULT_THREADS=4

# Timeout for external commands (seconds)
COMMAND_TIMEOUT=60

# Maximum file size to process (find format: k, M, G)
MAX_FILESIZE=100M

# Temporary directory (uses system default if empty)
TEMP_DIR=""

# ============================================
# OCR Settings
# ============================================

# OCR languages (space-separated, tesseract format)
OCR_LANGS="eng rus"

# Minimum text length from pdf2txt before attempting OCR on images
OCR_MIN_TEXT=100

# Maximum images to OCR per document (0 = unlimited)
OCR_MAX_IMAGES=10

# Completely disable OCR (1 = disabled)
OCR_DISABLED=0

# ============================================
# Audio Transcription Settings
# ============================================

# Audio transcription languages (space-separated, vosk format)
AUDIO_LANGS="en-us ru"

# Enable/disable audio transcription (1 = disabled)
AUDIO_DISABLED=0

# ============================================
# Image Processing
# ============================================

# Save image thumbnails (set path or leave empty to disable)
IMAGES=""

# Thumbnail size
IMAGE_THUMBNAIL_SIZE="640x480"

# ============================================
# Session Management
# ============================================

# Use SQLite for session tracking (faster for large crawls)
USE_SQLITE_SESSION=1

# Session database location (relative to index)
SESSION_DB_SUFFIX=".session.db"

# ============================================
# Logging
# ============================================

# Log level: DEBUG, INFO, WARN, ERROR
LOG_LEVEL="INFO"

# Log file (empty = stderr only)
LOG_FILE=""

# ============================================
# Performance
# ============================================

# CSV write buffer size (bytes)
CSV_BUFFER_SIZE=65536

# Batch size for OpenSearch bulk operations
OPENSEARCH_BATCH_SIZE=500

# ============================================
# Exclusions
# ============================================

# Directories to exclude (comma-separated, case-insensitive)
EXCLUDE_DIRS="Windows,Program Files,Program Files (x86),.git,.svn,node_modules,__pycache__"

# File patterns to exclude (find format)
EXCLUDE_PATTERNS=""

# MIME types to skip
EXCLUDE_MIMES=""

# ============================================
# Deduplication
# ============================================

# Enable content deduplication by hash
DEDUPE_ENABLED=0

# Hash algorithm: md5, sha1, sha256
DEDUPE_HASH="md5"

# ============================================
# Network Crawling (SMB/NFS/FTP)
# ============================================

# Mount timeout (seconds)
MOUNT_TIMEOUT=10

# Crawl timeout per share (seconds)
CRAWL_TIMEOUT=300

# SMB versions to try (comma-separated)
SMB_VERSIONS="3.0,2.1,2.0,1.0"

# ============================================
# OpenSearch Settings
# ============================================

# OpenSearch host (read from environment or here)
# OPENSEARCH_HOST="localhost"
# OPENSEARCH_PORT="9200"
# OPENSEARCH_USE_SSL="true"
# OPENSEARCH_VERIFY_CERTS="false"

# Index settings
OPENSEARCH_SHARDS=1
OPENSEARCH_REPLICAS=0
